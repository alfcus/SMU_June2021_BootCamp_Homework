{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I predict that the Random Forest Classifier will perform better on the UNSCALED data\n",
    "\n",
    "I predict the Logistic Regression will perform better on the SCALED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', None) # observe all columns in dataframe\n",
    "\n",
    "# models to observe\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# reporting\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# for scaling data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe ratio of training and test split\n",
    "len(train_df) / (len(train_df) + len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe target feature in training set\n",
    "train_df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe target feature in testing set\n",
    "test_df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_df[\"loan_status\"] = [1 if x == \"high_risk\" else 0 for x in train_df.loan_status]\n",
    "\n",
    "# View of categorical data \n",
    "train_categorical_df = train_df.select_dtypes(include='object')\n",
    "train_categorical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_categorical_df.columns:\n",
    "    print(train_categorical_df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data to numeric\n",
    "train_categorical_df2 = pd.get_dummies(train_categorical_df)\n",
    "train_categorical_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and merge all numeric data\n",
    "numeric_train_df = train_df.select_dtypes(exclude=\"object\")\n",
    "train_df_final = pd.merge(numeric_train_df, train_categorical_df2, left_index=True, right_index=True)\n",
    "train_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_df[\"loan_status\"] = [1 if x == \"high_risk\" else 0 for x in test_df.loan_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View of categorical data \n",
    "test_categorical_df = test_df.select_dtypes(include='object')\n",
    "test_categorical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_categorical_df.columns:\n",
    "    print(test_categorical_df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data to numeric\n",
    "test_categorical_df2 = pd.get_dummies(test_categorical_df)\n",
    "test_categorical_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and merge all numeric data\n",
    "numeric_test_df = test_df.select_dtypes(exclude=\"object\")\n",
    "test_df_final = pd.merge(numeric_test_df, test_categorical_df2, left_index=True, right_index=True)\n",
    "test_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for col in train_df_final.columns:\n",
    "    if col not in test_df_final.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final[\"debt_settlement_flag_Y\"] = 0\n",
    "test_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final checks\n",
    "train_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing 'Unnamed', 'index', and 'pymnt_plan_n' columns; 'pymnt_plan_n' removed due to not having corresponding 'y' column\n",
    "remove_cols = ['Unnamed: 0', 'index', 'pymnt_plan_n']\n",
    "\n",
    "train_df_final.drop(remove_cols, axis=1, inplace=True)\n",
    "test_df_final.drop(remove_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_final.drop(\"loan_status\", axis=1)\n",
    "y_train = train_df_final.loan_status\n",
    "\n",
    "X_test = test_df_final.drop(\"loan_status\", axis=1)\n",
    "y_test = test_df_final.loan_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(f'Training Score: {lr.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {lr.score(X_test, y_test)}')\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=25)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(f'Training Score: {rf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {rf.score(X_test, y_test)}')\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the training data\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the dataset with the scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "lr_sc = LogisticRegression()\n",
    "lr_sc = lr_sc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lr_sc.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training Score: {lr_sc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {lr_sc.score(X_test_scaled, y_test)}')\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "rf_sc = RandomForestClassifier(random_state=42, n_estimators=25)\n",
    "rf_sc = rf_sc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = rf_sc.predict(X_test_scaled)\n",
    "\n",
    "print(f'Training Score: {rf_sc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {rf_sc.score(X_test_scaled, y_test)}')\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the unscaled data, the Random Forest Classifier performs better having a testing score of 0.63207 while the Logistic Regression only has a testing score of 0.51595. The f1-score is very low for predicting \"high risk\" loans in the Logistic Regression. The prediction of the Random Forest Classifier performing better with unscaled data is correct.\n",
    "\n",
    "In the scaled data, the Logistic Regression performs better having a testing score of 0.76733 while the Random Forest Classifier only has a testing score of 0.63270. The f1-score is low for predicting \"low risk\" loans in the Random Forest Classifier compared to the Logistic Regression. The prediction of the Logistic Regression performing better with scaled data is correct.\n",
    "\n",
    "Additional Observation: The scaled data in the Random Forest Classifier slightly improved the testing score while the Logistic Regression testing score was greatly improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
